# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

A multi-agent AI system that analyzes professional strengths through psychometric surveys to automatically generate personal branding reports. Built with Next.js 14 and Claude Agent SDK.

**Current Implementation Status:**
- âœ… **Phase 1 (ë¬´ë£Œ í‹°ì–´) - LIVE**: PSA Survey â†’ Brief Report â†’ Public Web Profile
- ğŸš§ **Phase 2 (ìœ ë£Œ í‹°ì–´) - COMING SOON**: Resume Upload â†’ Enhanced Questions â†’ Full Report

**Key outputs (Phase 1):**
- Brief analysis report with persona identification (10 types)
- Public web profile page (shareable URL at `/p/[slug]`)
- Radar chart visualization of 5 professional dimensions

**User flow (Current):**
```
/ (Landing) â†’ /survey (60 questions) â†’ /survey-result (Brief report) â†’ /p/[slug] (Public profile)
```

**User flow (Planned - Phase 2):**
```
/ â†’ /survey â†’ /survey-result â†’ /upload â†’ /questions â†’ /generating â†’ /result
```

## Development Commands

```bash
# Development
npm run dev              # Start dev server at http://localhost:3000
npm run build           # Build for production
npm run start           # Start production server
npm run lint            # Run ESLint

# Database
# Run migration in Supabase SQL Editor: supabase/migrations/001_initial_schema.sql
# Create storage buckets manually: resumes, portfolios, assets, reports (all public)
```

## Environment Setup

Required environment variables in `.env.local`:

```bash
ANTHROPIC_API_KEY=           # Claude API key (required for all agents)
NEXT_PUBLIC_SUPABASE_URL=    # Supabase project URL
NEXT_SUPABASE_PUBLISHABLE_KEY=   # Supabase publishable key (replaces anon key)
NEXT_SUPABASE_SECRET_KEY=   # Supabase secret key (replaces service_role key)
```

## PSA Survey System (NEW)

**Professional Strength Assessment** - A 60-question psychometric survey that analyzes user strengths across 5 dimensions. The brief report is generated without requiring resume upload (free tier), while the full branding report requires resume and portfolio (paid tier).

### Survey Flow

```
1. PSA Survey (60Q) â†’ 2. Brief Report (ë¬´ë£Œ) â†’ 3. File Upload â†’ 4. Enhanced Questions (9Q) â†’ 5. Full Report (ìœ ë£Œ)
```

**Key Features:**
- **60 questions** across 5 categories (12 questions each)
- **7-point Likert scale** (1: ì „í˜€ ê·¸ë ‡ì§€ ì•Šë‹¤ ~ 7: ë§¤ìš° ê·¸ë ‡ë‹¤)
- **10 persona types** mapped from top 2 category combinations
- **Brief analysis report** with radar chart and strengths summary (ì´ë ¥ì„œ ì—†ì´ PSAë§Œìœ¼ë¡œ ìƒì„±)
- **Enhanced questioning** - 9 questions (Soul Questions 3 + Expertise 4 + Edge 2)

**5 Categories:**
1. **í˜ì‹  ì‚¬ê³ ** (Innovation & Vision)
2. **ì² ì € ì‹¤í–‰** (Execution & Discipline)
3. **ëŒ€ì¸ ì˜í–¥** (Influence & Impact)
4. **í˜‘ì—… ê³µê°** (Collaboration & Synergy)
5. **ìƒí™© íšŒë³µ** (Resilience & Adaptability)

**10 Persona Types:**
- ì „ëµì  ì„¤ê³„ì (Innovation + Execution)
- ì‹œì¥ íŒŒê´´ì (Innovation + Influence)
- ì°½ì˜ì  ì´‰ë§¤ (Innovation + Collaboration)
- ì ì‘í˜• ì„ êµ¬ì (Innovation + Resilience)
- í¼í¬ë¨¼ìŠ¤ ë“œë¼ì´ë²„ (Execution + Influence)
- ì‹ ë¢°ì˜ ì¤‘ì¶” (Execution + Collaboration)
- ê°•ì² ì˜ ì™„ê²°ì (Execution + Resilience)
- ê³µê°í˜• ë¦¬ë” (Influence + Collaboration)
- í”ë“¤ë¦¬ì§€ ì•ŠëŠ” ëŒ€ë³€ì¸ (Influence + Resilience)
- íšŒë³µíƒ„ë ¥ì  ì¤‘ì¬ì (Collaboration + Resilience)

## Multi-Agent Architecture

### Current Implementation (Phase 1 - LIVE)

**Template-Based Brief Report Generation:**
```
/api/survey/analyze
â”œâ”€ Template Selector â†’ BriefAnalysis (Rule-based, <1ì´ˆ)
â””â”€ Database Insert  â†’ Web profile data (/p/[slug])
```

**Note:** Currently uses template-based generation instead of AI agents for cost efficiency ($0 vs $0.002-0.005 per report). Phase 2 will introduce full multi-agent workflow.

### Planned Architecture (Phase 2 - COMING SOON)

The system will use 9 specialized AI agents orchestrated in a specific workflow:

**Brief Report Generation (Rule-Based Template System):**
- **Processing:** Template-based (no LLM calls)
- **Speed:** <1 second (vs 10-30s with AI)
- **Cost:** $0 (vs $0.002-0.005 with AI)
- **Content:**
  - `strengthsSummary`: 30 pre-written templates (10 personas Ã— 3 variants)
  - `strengthsScenarios`: 22 scenario templates matched to top categories
  - `shadowSides`: Generated from persona metadata + reframing
  - `brandingKeywords`: From persona metadata
- **Templates:** `lib/templates/persona-templates.ts`, `lib/templates/scenario-pool.ts`
- **Selection logic:** `lib/templates/template-selector.ts` (variant: balanced/spiked/mixed)

**Phase 2 (ìœ ë£Œ í‹°ì–´) - OrchestratorAgent ì „ì²´ ì›Œí¬í”Œë¡œìš°:**
```
OrchestratorAgent (agents/orchestrator.ts)
â”œâ”€ Step 1: Data Collection (Parallel)
â”‚  â”œâ”€ ResumeParserAgent       â†’ ParsedResume (personal info, experience, skills)
â”‚  â””â”€ PortfolioAnalyzerAgent  â†’ PortfolioAnalysis (projects, strengths, style)
â”‚
â”œâ”€ Step 2: Brand Strategy
â”‚  â””â”€ BrandStrategistAgent    â†’ BrandStrategy (essence, value prop, audience)
â”‚
â”œâ”€ Step 3: Content Generation (Parallel)
â”‚  â”œâ”€ ContentWriterAgent      â†’ ReportContent (story, strengths, vision)
â”‚  â””â”€ KeywordExtractorAgent   â†’ Keywords (SEO keywords, hashtags)
â”‚
â”œâ”€ Step 4: Report Assembly
â”‚  â””â”€ ReportAssemblerAgent    â†’ AssembledReport (structured pages)
â”‚
â””â”€ Step 5: Completion
```

**Note:** `QuestionDesignerAgent`ëŠ” ë³„ë„ API (`/api/questions/generate`)ì—ì„œ ì‹¤í–‰ë˜ë©°, PSA ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 9ê°œ ì§ˆë¬¸ ìƒì„± (Soul Questions 3 + Expertise 4 + Edge 2)

### Agent Communication Pattern

All agents extend `BaseAgent<TInput, TOutput>` with:
- `process(input, context)`: Main processing method
- `callLLM(userMessage, previousMessages)`: Claude API calls with auto-retry
- `success(data, metadata)` / `failure(error)`: Standardized results

Context object contains:
- `sessionId`: Unique session identifier
- `data`: Shared data between agents

### Key Design Principles

**1. Agent Isolation:** Each agent has a single responsibility and can be modified independently

**2. Type Safety:** All agent inputs/outputs use TypeScript interfaces defined in `types/` directory:
   - `types/resume.ts` - ParsedResume
   - `types/portfolio.ts` - PortfolioAnalysis
   - `types/survey.ts` - SurveyQuestion, SurveyResponse, BriefAnalysis, PersonaMetadata [NEW]
   - `types/brand.ts` - BrandStrategy, Keywords, BrandingQuestions
   - `types/report.ts` - ReportContent, AssembledReport, WebProfile

**3. Error Resilience:** Built-in retry logic with exponential backoff (`lib/retry.ts`):
   - All LLM calls automatically retry up to 3 times
   - Retries on network errors (408, 429, 500, 502, 503, 504)
   - Exponential backoff: 2s, 4s, 8s delays

**4. Progress Tracking:** `ProgressTracker` class updates database at each workflow step:
   - 10 total steps tracked in `report_sessions` table
   - Real-time status updates: pending â†’ in_progress â†’ completed/failed

## File Parsing System

Files are parsed immediately on upload (not during generation):

```typescript
// app/api/upload/route.ts
const buffer = Buffer.from(await file.arrayBuffer());
const parsed = await parseFile(buffer, file.type);  // Uses pdf-parse or mammoth
// Stores parsed.text and parsed.metadata in uploads.parsed_data
```

Agents receive pre-parsed text from database, not raw files.

## Database Schema

PostgreSQL via Supabase with 9 main tables:

**Core Tables:**
- `report_sessions` - User sessions (email, status, survey_completed, brief_report_generated, timestamps)
- `uploads` - File uploads with `parsed_data` JSONB column containing extracted text
- `question_answers` - User questionnaire responses

**PSA Survey Tables (NEW):**
- `survey_questions` - Fixed 50-question PSA survey (version controlled)
- `survey_responses` - User answers to survey questions (1-7 Likert scale)
- `brief_reports` - AI-generated brief analysis (persona, scores, strengths)

**Output Tables:**
- `reports` - Generated reports (brand_strategy, content, pdf_url)
- `web_profiles` - Public profiles (slug, profile_data, seo_data, is_public)

**Migrations:**
- `001_initial_schema.sql` - Core tables
- `002_strengthen_rls.sql` - RLS policies
- `003_add_unique_constraints.sql` - Constraints
- `004_add_survey_system.sql` - PSA survey tables
- `005_seed_survey_questions.sql` - Original 100 survey questions (deprecated)
- `006_update_survey_to_50_questions.sql` - 50 survey questions (deprecated)
- `007_update_survey_to_60_questions.sql` - **Current: 60 survey questions** (5 categories Ã— 12 questions)

**Storage buckets:** Must be manually created in Supabase dashboard as public buckets.

## PSA Survey API Routes (NEW)

**Survey Management:**
- `GET /api/survey/questions` - Retrieve 50 survey questions organized by category
- `POST /api/survey/submit` - Submit user's 50 answers (validates completeness)
- `POST /api/survey/analyze` - Trigger SurveyAnalyzerAgent to generate brief report
- `GET /api/survey/result?sessionId=xxx` - Retrieve brief analysis results

**Enhanced Question Generation:**
- `POST /api/questions/generate` - Now accepts PSA results to generate 7-10 focused questions (instead of 15-20)

## API Route Patterns

All API routes return consistent JSON:
```typescript
// Success
{ data: T, message?: string }

// Error
{ error: string }
```

File uploads use `FormData`:
```typescript
formData.append('file', file);
formData.append('sessionId', sessionId);
formData.append('fileType', 'resume' | 'portfolio');
```

Session management via localStorage on client:
```typescript
const sessionId = localStorage.getItem('sessionId');
```

## Frontend Pages

### âœ… Implemented Pages (Phase 1)

1. `/` - Landing page with dark glassmorphism design
2. `/survey` - PSA 60-question survey with progress tracking (10 pages Ã— 6 questions)
3. `/survey-result` - Brief analysis with persona card, radar chart, strengths summary
4. `/p/[slug]` - Public web profile (shareable, SEO-optimized)

### ğŸš§ Coming Soon Pages (Phase 2)

5. `/start` - Currently redirects to `/survey`
6. `/upload` - Resume and portfolio file upload (ComingSoon component)
7. `/questions` - Enhanced questionnaire (ComingSoon component)
8. `/generating` - Full report generation progress (ComingSoon component)
9. `/result` - Full branding report with brand strategy (ComingSoon component)

**Design System:**
- Upload/Questions pages: `bg-gradient-to-br from-blue-50 to-indigo-100`
- Survey pages: **Dark glassmorphism** `bg-gradient-to-br from-slate-900 via-indigo-950 to-slate-900` [UPDATED]
  - Header/cards: `bg-white/5` + `backdrop-blur-md` (glassmorphism)
  - Question cards: `bg-white/90` + `backdrop-blur-md` (high readability)
  - Buttons: Gradient `from-indigo-600 to-purple-600` with glow effects
  - Likert scale: Enhanced borders (`border-4 sm:border-[5px]`) + ring effects on selection
- Survey result: Dark gradient hero `from-purple-900 via-indigo-900 to-blue-900`
- Cards: `bg-white rounded-2xl shadow-lg`
- Buttons: Uses `@/components/ui/button` (shadcn/ui)
- Icons: lucide-react
- Charts: recharts for radar visualization [NEW]

## Common Patterns

### PSA Survey Integration Example

The `SurveyAnalyzerAgent` demonstrates how to integrate psychometric analysis:

```typescript
// agents/survey-analyzer.ts
export class SurveyAnalyzerAgent extends BaseAgent<SurveyResponse, BriefAnalysis> {
  async process(input: SurveyResponse, context: AgentContext) {
    // 1. Calculate category scores (average 1-7, normalize to 0-100)
    const categoryScores = this.calculateCategoryScores(input.answers);

    // 2. Identify top 2 categories
    const topCategories = this.getTopCategories(categoryScores);

    // 3. Map to persona (e.g., innovation+execution â†’ "ì „ëµì  ì„¤ê³„ì")
    const persona = getPersonaByCategories(topCategories);

    // 4. Generate AI analysis
    const analysis = await this.callLLM(`
      ì‚¬ìš©ìì˜ PSA ì ìˆ˜ë¥¼ ë¶„ì„í•˜ì—¬ ê°•ì  ìš”ì•½ê³¼ ì£¼ì˜ì ì„ ì‘ì„±í•˜ì„¸ìš”.
      í˜ë¥´ì†Œë‚˜: ${persona.title}
      ì ìˆ˜: ${JSON.stringify(categoryScores)}
    `);

    return this.success({ categoryScores, persona, strengthsSummary: analysis });
  }
}
```

### Adding a New Agent

1. Create file in `agents/` extending `BaseAgent<TInput, TOutput>`
2. Define input/output interfaces in `types/`
3. Implement `async process(input, context): Promise<AgentResult<TOutput>>`
4. Add to orchestrator workflow with progress tracking
5. Update orchestrator's `process()` method with new step

### Modifying Agent Logic

Agents use system prompts (Korean) to guide Claude's behavior. To change output:
1. Update system prompt in agent constructor
2. Modify output interface in `types/`
3. Update downstream agents that consume the output
4. Test the full workflow

### Testing Agent Workflows

Trigger via API route:
```bash
curl -X POST http://localhost:3000/api/generate \
  -H "Content-Type: application/json" \
  -d '{"sessionId": "your-session-id"}'
```

Monitor progress in `report_sessions.status` and console logs.

## Language and Localization

- **UI text:** Korean (all component text, API messages)
- **System prompts:** Korean (agent instructions to Claude)
- **Input:** Accepts both Korean and English (resume, portfolio, questionnaire)
- **Output:** Korean (all generated report content)

## Known Limitations

- No authentication system - sessions identified by email only
- File size limit: 10MB per upload
- Supported formats: PDF, DOCX (resume/portfolio), PNG, JPG (portfolio only)
- No real-time UI updates during generation (polling required)
- PSA survey: All 60 questions must be answered to submit (no partial saves except localStorage)
- Brief report generation is synchronous (may take 10-20 seconds for LLM analysis)

## Troubleshooting

**Claude API errors:** Check `ANTHROPIC_API_KEY` and rate limits. Retry logic handles transient failures automatically.

**File upload failures:** Verify Supabase storage buckets exist and are public. Check file size (<10MB) and type.

**Agent workflow hangs:** Check console logs for specific agent failure. Each agent logs start/completion. Progress tracked in database.

**Missing parsed text:** Files must be PDF/DOCX for text extraction. Images don't extract text. Check `uploads.parsed_data` in database.

**Survey errors:** Ensure migrations 004 and 006 are applied. Verify `survey_questions` table has 60 active rows (version 2). Check `survey_completed` and `brief_report_generated` flags in `report_sessions`.

**Persona mapping issues:** Verify top 2 categories exist in `PersonaMap` (types/survey.ts). Check that category keys match pattern: `"category1-category2"`.

## Playwright E2E Testing

**End-to-End testing system** powered by Playwright with AI-based failure analysis.

### Testing Status

**âœ… Active Tests (Phase 1 - Implemented Features):**
- `survey.spec.ts` - PSA survey functionality
- `survey-result.spec.ts` - Brief report display
- `public-profile.spec.ts` - Public web profile
- `user-flow.spec.ts` - Complete Phase 1 journey (adjusted for current flow)

**â¸ï¸  Skipped Tests (Phase 2 - Coming Soon):**
- `start.spec.ts` - Email collection (deprecated, now redirects to survey)
- `upload.spec.ts` - File upload (not yet implemented)
- `questions.spec.ts` - Enhanced questionnaire (not yet implemented)
- `generating.spec.ts` - Report generation (not yet implemented)
- `result.spec.ts` - Full report results (not yet implemented)

### Testing Commands

```bash
# Run only Phase 1 (active) tests
npm run test:e2e -- tests/e2e/survey.spec.ts tests/e2e/survey-result.spec.ts tests/e2e/public-profile.spec.ts

# Run specific test file
npm run test:e2e -- tests/e2e/survey.spec.ts

# Run in headed mode (show browser)
npm run test:e2e:headed

# Debug mode (step-by-step execution)
npm run test:e2e:debug

# View test report
npm run test:e2e:report
```

### Test Structure

```
tests/
â”œâ”€â”€ e2e/                        # E2E test scenarios (9 files)
â”‚   â”œâ”€â”€ start.spec.ts          # Email entry & session creation
â”‚   â”œâ”€â”€ survey.spec.ts         # 60-question PSA survey
â”‚   â”œâ”€â”€ survey-result.spec.ts  # Brief report (ë¬´ë£Œ í‹°ì–´)
â”‚   â”œâ”€â”€ upload.spec.ts         # Resume/portfolio upload (ìœ ë£Œ ì „í™˜)
â”‚   â”œâ”€â”€ questions.spec.ts      # Enhanced questionnaire (9 questions)
â”‚   â”œâ”€â”€ generating.spec.ts     # Full report generation progress
â”‚   â”œâ”€â”€ result.spec.ts         # Final branding report output
â”‚   â”œâ”€â”€ public-profile.spec.ts # Public web profile
â”‚   â””â”€â”€ user-flow.spec.ts      # Complete user journey
â”œâ”€â”€ fixtures/                   # Test data & helpers
â”‚   â”œâ”€â”€ session-manager.ts     # Session lifecycle management
â”‚   â”œâ”€â”€ test-files.ts          # Mock PDF/DOCX files
â”‚   â”œâ”€â”€ survey-answers.ts      # Pre-defined survey responses
â”‚   â””â”€â”€ questionnaire-answers.ts
â”œâ”€â”€ helpers/                    # Utility functions
â”‚   â”œâ”€â”€ network-logger.ts      # API call logging
â”‚   â”œâ”€â”€ console-logger.ts      # Browser console capture
â”‚   â”œâ”€â”€ screenshot-helper.ts   # Screenshot capture
â”‚   â””â”€â”€ report-writer.ts       # Report generation
â”œâ”€â”€ agents/                     # QA AI Agent
â”‚   â””â”€â”€ qa-analyzer-agent.ts   # AI-powered failure analysis
â””â”€â”€ reports/                    # Test outputs
    â”œâ”€â”€ screenshots/            # Failure screenshots
    â”œâ”€â”€ network-logs/           # API logs (JSON)
    â””â”€â”€ ai-analysis/            # AI analysis reports (Markdown)
```

### Key Features

âœ… **Complete User Flow Testing** - Tests all 8 pages from start to result
âœ… **AI-Powered Failure Analysis** - Claude analyzes failures with screenshots
âœ… **Network Logging** - Captures all API calls and responses
âœ… **Session Management** - Automatic test data creation and cleanup
âœ… **CI/CD Integration** - Automated testing on GitHub Actions
âœ… **Multimodal Analysis** - Claude reads screenshots to identify UI issues

### QA Analyzer Agent

When tests fail, the QA Analyzer Agent automatically:

1. **Analyzes screenshot** - Identifies UI state, error messages, loading indicators
2. **Reviews network logs** - Checks API responses, status codes, timing
3. **Examines console errors** - Parses JavaScript errors and stack traces
4. **Generates report** - Provides root cause, impacted components, and suggested fixes

**Example AI Analysis Output:**

```markdown
## Root Cause
API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ: /api/survey/submitì´ 30ì´ˆ ë‚´ ì‘ë‹µí•˜ì§€ ì•ŠìŒ.
LLM ë¶„ì„ ì†Œìš” ì‹œê°„(10-30ì´ˆ)ì´ Playwrightì˜ ê¸°ë³¸ timeout(10ì´ˆ)ì„ ì´ˆê³¼í•¨.

## Suggested Fixes
1. **playwright.config.ts**: timeoutì„ 60000msë¡œ ì¦ê°€
2. **survey.spec.ts**: waitForResponse timeoutì„ 30000msë¡œ ì„¤ì •
3. **app/api/survey/submit/route.ts**: ë¹„ë™ê¸° ì²˜ë¦¬ ê°œì„  (ë°±ê·¸ë¼ìš´ë“œ job ê³ ë ¤)

## Severity
HIGH - í•µì‹¬ User Flow ì°¨ë‹¨
```

### Test Execution Flow

```
1. beforeEach â†’ Create session via SessionManager
2. Test logic â†’ Navigate pages, interact with UI, verify results
3. On failure â†’ Capture screenshot + network logs + console errors
4. AI Analysis â†’ QA Agent analyzes failure data
5. Generate report â†’ Markdown report saved to tests/reports/ai-analysis/
6. afterEach â†’ Cleanup session from Supabase
```

### Environment Variables (Testing)

Required for E2E tests:

```bash
ANTHROPIC_API_KEY=           # For QA Analyzer Agent
NEXT_PUBLIC_SUPABASE_URL=    # For SessionManager cleanup
NEXT_SUPABASE_SECRET_KEY=   # For database cleanup operations
```

### CI/CD

GitHub Actions workflow (`.github/workflows/e2e-tests.yml`):

- **Triggers**: Push to main/develop, Pull Requests
- **Runs**: Playwright tests on ubuntu-latest
- **Artifacts**: Screenshots, network logs, AI analysis reports (on failure)
- **Duration**: ~15-20 minutes for full test suite

### Testing Best Practices

- **Independent tests**: Each test creates its own session, no shared state
- **Cleanup**: `afterEach` hook deletes test data from Supabase
- **Timeouts**: LLM operations use extended timeouts (60-90s)
- **Fixtures**: Use pre-defined fixtures for consistent test data
- **Mock when needed**: Mock API responses for error scenarios

### Common Test Patterns

**Session creation:**
```typescript
const sessionManager = createSessionManager();
const sessionId = await sessionManager.createSession(page, 'test@example.com');
```

**60-question survey shortcut:**
```typescript
// Instead of clicking 60 buttons, inject answers via localStorage
const answers = generateBalancedAnswers(60);
await page.evaluate((data) => {
  localStorage.setItem('survey-answers', JSON.stringify(data));
}, answers);
```

**Network logging:**
```typescript
const networkLogger = createNetworkLogger();
networkLogger.start(page);
// ... perform actions ...
const apiLogs = networkLogger.getAPILogs();
```

**AI analysis on failure:**
```typescript
try {
  // Test logic
} catch (error) {
  const screenshotPath = await captureFailureScreenshot(page, testName);
  const analysis = await qaAgent.analyzeFailure({
    testName, error: error.message, screenshotPath, networkLogs
  });
  saveAIAnalysisReport(testName, analysis.reportMarkdown);
  throw error; // Re-throw to fail the test
}
```

### Troubleshooting E2E Tests

**"sessionId not found" errors:**
- Ensure `SessionManager.createSession()` is called in `beforeEach`
- Check localStorage persistence between page navigations

**Timeout errors on /survey-result:**
- LLM analysis takes 10-30 seconds, increase `waitForURL` timeout to 90000ms

**Cleanup failures:**
- Verify `NEXT_SUPABASE_SECRET_KEY` is set correctly
- Check foreign key constraints (delete in correct order)

**AI analysis not generating:**
- Confirm `ANTHROPIC_API_KEY` is set in `.env.local`
- Check API rate limits if many tests fail simultaneously

For detailed testing documentation, see `tests/README.md`.
