name: E2E Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch: # Allow manual trigger

jobs:
  e2e-test:
    name: Playwright E2E Tests (Shard ${{ matrix.shard }}/${{ strategy.job-total }})
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4]

    env:
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      # Use separate test database if available, fallback to production
      NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.TEST_SUPABASE_URL || secrets.NEXT_PUBLIC_SUPABASE_URL }}
      NEXT_SUPABASE_PUBLISHABLE_KEY: ${{ secrets.TEST_SUPABASE_PUBLISHABLE_KEY || secrets.NEXT_SUPABASE_PUBLISHABLE_KEY }}
      NEXT_SUPABASE_SECRET_KEY: ${{ secrets.TEST_SUPABASE_SECRET_KEY || secrets.NEXT_SUPABASE_SECRET_KEY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Cache Playwright browsers
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-${{ runner.os }}-${{ hashFiles('package-lock.json') }}
          restore-keys: |
            playwright-${{ runner.os }}-

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install chromium

      - name: Install system dependencies for Playwright
        run: npx playwright install-deps chromium

      - name: Build Next.js application
        run: npm run build
        env:
          NODE_ENV: production

      - name: Run E2E tests (Shard ${{ matrix.shard }}/${{ strategy.job-total }})
        run: npx playwright test --shard=${{ matrix.shard }}/${{ strategy.job-total }}
        continue-on-error: true
        id: e2e-tests

      - name: Upload Playwright report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report-${{ matrix.shard }}
          path: playwright-report/
          retention-days: 7

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.shard }}
          path: tests/reports/
          retention-days: 7

      - name: Upload AI analysis reports
        # Only run AI analysis if:
        # 1. Tests failed AND
        # 2. It's a PR with 'run-qa-agent' label OR manual workflow trigger
        if: |
          failure() && (
            (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'run-qa-agent')) ||
            github.event_name == 'workflow_dispatch'
          )
        uses: actions/upload-artifact@v4
        with:
          name: ai-analysis-reports-${{ matrix.shard }}
          path: tests/reports/ai-analysis/
          retention-days: 14

      - name: Upload failure screenshots
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failure-screenshots-${{ matrix.shard }}
          path: tests/reports/screenshots/
          retention-days: 14

      - name: Upload network logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: network-logs-${{ matrix.shard }}
          path: tests/reports/network-logs/
          retention-days: 7

      - name: Fail workflow if tests failed
        if: steps.e2e-tests.outcome == 'failure'
        run: exit 1

  # Merge test results from all shards and post PR comment
  report-results:
    name: Report Test Results
    if: always() && github.event_name == 'pull_request'
    needs: e2e-test
    runs-on: ubuntu-latest
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          path: test-results
          merge-multiple: true

      - name: Comment PR with test results
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            let body = '## ğŸ§ª E2E Test Results (Parallelized)\n\n';
            body += `**Workflow Run**: [View Details](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n\n`;

            // Try to read merged test results
            const resultsDir = 'test-results';
            const resultFiles = fs.existsSync(resultsDir)
              ? fs.readdirSync(resultsDir).filter(f => f.endsWith('.json'))
              : [];

            if (resultFiles.length > 0) {
              let totalPassed = 0, totalFailed = 0, totalSkipped = 0;

              resultFiles.forEach(file => {
                try {
                  const data = JSON.parse(fs.readFileSync(path.join(resultsDir, file), 'utf8'));
                  if (data.stats) {
                    totalPassed += data.stats.expected || 0;
                    totalFailed += data.stats.unexpected || 0;
                    totalSkipped += data.stats.skipped || 0;
                  }
                } catch (e) {
                  console.log(`Failed to parse ${file}`);
                }
              });

              const total = totalPassed + totalFailed + totalSkipped;
              const successRate = total > 0 ? Math.round((totalPassed/total)*100) : 0;

              body += `- âœ… **Passed**: ${totalPassed}/${total}\n`;
              body += `- âŒ **Failed**: ${totalFailed}/${total}\n`;
              body += `- â­ï¸ **Skipped**: ${totalSkipped}/${total}\n`;
              body += `- ğŸ“Š **Success Rate**: ${successRate}%\n`;
              body += `- ğŸš€ **Shards**: 4 (parallel execution)\n\n`;

              if (totalFailed > 0) {
                body += '### âš ï¸ Failed Tests\n';
                body += 'Check the [test artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) for detailed failure information.\n\n';
                body += '> ğŸ’¡ **Tip**: Add the `run-qa-agent` label to this PR to enable AI-powered failure analysis.\n';
              } else {
                body += '### ğŸ‰ All tests passed!\n';
              }
            } else {
              body += 'âŒ Test results not available. Check [workflow logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}).\n';
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
